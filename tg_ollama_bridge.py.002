#!/usr/bin/python3
# -*- coding: utf-8 -*-
import os
import sys
import json
import html
import asyncio
import tempfile
import subprocess
from typing import Dict, Optional

import aiohttp
from telegram import Update
from telegram.constants import ParseMode, ChatAction
from telegram.error import BadRequest, TelegramError
from telegram.ext import (
    ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters
)

# =============== Config load ===============
BASE_PATH = os.path.abspath("./")
CFG_PATH = os.path.join(BASE_PATH, "config", "telegram.json")

if not os.path.exists(CFG_PATH):
    print(f"[ERRORE] Config Telegram mancante: {CFG_PATH}", file=sys.stderr)
    sys.exit(1)

try:
    with open(CFG_PATH, "r", encoding="utf-8") as f:
        CFG = json.load(f)
except Exception as e:
    print(f"[ERRORE] Impossibile leggere/parsare {CFG_PATH}: {e}", file=sys.stderr)
    sys.exit(1)

BOT_TOKEN: str = (CFG.get("bot_token") or "").strip()
APP_BASE_URL: str = (CFG.get("app_base_url") or "http://127.0.0.1:5000/json").rstrip("/")
DEFAULT_MODEL: str = CFG.get("default_model", "gemma2:2b")
ALLOWED_CHAT_IDS = set(CFG.get("allowed_chat_ids", []))
TIMEOUT_SEC: int = int(CFG.get("timeout_sec", 60))
ASR_CFG = CFG.get("asr", {}) or {}
ASR_BACKEND = (ASR_CFG.get("backend") or "faster-whisper").lower()

if not BOT_TOKEN:
    print("[ERRORE] bot_token non impostato in config/telegram.json", file=sys.stderr)
    sys.exit(1)

# =============== Stato per chat ===============
CHAT_MODEL: Dict[int, str] = {}

def _is_allowed(chat_id: int) -> bool:
    return (not ALLOWED_CHAT_IDS) or (chat_id in ALLOWED_CHAT_IDS)

def _get_model_for_chat(chat_id: int) -> str:
    return CHAT_MODEL.get(chat_id, DEFAULT_MODEL)

def _set_model_for_chat(chat_id: int, model: str):
    CHAT_MODEL[chat_id] = (model or "").strip()

def chunk_text(text: str, max_len: int = 3800):
    text = text or ""
    for i in range(0, len(text), max_len):
        yield text[i:i+max_len]

def _html(msg: str) -> str:
    return html.escape(msg or "")

# =============== Client verso app-ollama.py ===============
async def query_app_ollama(session: aiohttp.ClientSession, text: str, model: str) -> str:
    url = APP_BASE_URL  # es: http://127.0.0.1:5000/json

    # Tentativo POST JSON
    try:
        async with session.post(
            url,
            json={"query": text, "model": model},
            timeout=TIMEOUT_SEC
        ) as resp:
            if resp.status == 200:
                data = await resp.json()
                if isinstance(data, dict):
                    return str(data.get("response", "")) or "(risposta vuota)"
    except Exception:
        pass

    # Fallback GET
    try:
        params = {"query": text, "model": model}
        async with session.get(url, params=params, timeout=TIMEOUT_SEC) as resp:
            if resp.status == 200:
                data = await resp.json()
                if isinstance(data, dict):
                    return str(data.get("response", "")) or "(risposta vuota)"
            return f"(errore: server ha risposto {resp.status} su GET {url})"
    except Exception as e:
        return f"(errore: impossibile contattare l'app Ollama {url} — {e})"

# =============== ASR: Faster-Whisper ===============
_whisper_model = None

def _load_faster_whisper_model():
    global _whisper_model
    if _whisper_model is not None:
        return _whisper_model
    try:
        # lazy import per partire anche senza ASR se uno non usa i vocali
        from faster_whisper import WhisperModel
    except Exception as e:
        raise RuntimeError(f"faster-whisper non installato: {e}. Esegui: pip install faster-whisper") from e

    model_name = ASR_CFG.get("model", "small")
    compute_type = ASR_CFG.get("compute_type", "int8")  # "int8", "int8_float16", "float16", "auto"
    _whisper_model = WhisperModel(model_name, compute_type=compute_type)
    return _whisper_model

def _ffmpeg_convert_to_wav16k_mono(in_path: str, out_path: str):
    """
    Converte qualsiasi input audio in WAV 16kHz mono con ffmpeg.
    """
    cmd = [
        "ffmpeg", "-y", "-i", in_path,
        "-ac", "1", "-ar", "16000", "-f", "wav",
        out_path
    ]
    # Usiamo subprocess.run per loggare eventuali errori
    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        raise RuntimeError(f"ffmpeg errore: {result.stderr.decode(errors='ignore')}")

async def transcribe_voice_ogg_to_text(ogg_bytes: bytes) -> str:
    """
    Riceve bytes OGG/OPUS da Telegram, li salva in tmp, converte in WAV 16k mono e trascrive.
    Ritorna testo (stringa) o solleva eccezione in caso di errori.
    """
    # 1) salva OGG temporaneo
    with tempfile.TemporaryDirectory() as tmpd:
        ogg_path = os.path.join(tmpd, "voice.ogg")
        wav_path = os.path.join(tmpd, "voice.wav")
        with open(ogg_path, "wb") as f:
            f.write(ogg_bytes)

        # 2) converti a WAV
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, _ffmpeg_convert_to_wav16k_mono, ogg_path, wav_path)

        # 3) carica modello whisper (lazy)
        def _do_transcribe():
            model = _load_faster_whisper_model()
            language = ASR_CFG.get("language") or None
            beam_size = ASR_CFG.get("beam_size", 5)
            segments, info = model.transcribe(
                wav_path,
                language=language,
                beam_size=beam_size
            )
            text = "".join(seg.text for seg in segments).strip()
            return text or ""

        text = await loop.run_in_executor(None, _do_transcribe)
        return text

# =============== Bot Handlers ===============
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    model = _get_model_for_chat(update.effective_chat.id)
    body = (
        "👋 Ciao! Questo bot inoltra i tuoi messaggi a <b>app-ollama.py</b> e ti restituisce la risposta.<br><br>"
        f"• Endpoint: <code>{_html(APP_BASE_URL)}</code><br>"
        f"• Modello attuale: <code>{_html(model)}</code><br><br>"
        "<b>Comandi utili</b><br>"
        "• <code>/model &lt;nome_modello&gt;</code> — imposta il modello (es. <code>gemma2:2b</code>, <code>llama3:latest</code>)<br>"
        "• <code>/health</code> — verifica connessione con l'app<br>"
        "• invia <b>messaggi vocali</b> per trascriverli e interrogarne il modello"
    )
    try:
        await update.message.reply_text(body, parse_mode=ParseMode.HTML, disable_web_page_preview=True)
    except BadRequest:
        await update.message.reply_text(
            f"Ciao! Endpoint: {APP_BASE_URL}\nModello: {model}\nUsa /model <nome_modello> o /health",
        )

async def cmd_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    if not context.args:
        current = _get_model_for_chat(update.effective_chat.id)
        await update.message.reply_text(
            f"Modello attuale: <code>{_html(current)}</code>\nUsa: <code>/model &lt;nome&gt;</code>",
            parse_mode=ParseMode.HTML,
        )
        return

    model = " ".join(context.args).strip()
    _set_model_for_chat(update.effective_chat.id, model)
    await update.message.reply_text(
        f"✅ Modello impostato su: <code>{_html(model)}</code>",
        parse_mode=ParseMode.HTML,
    )

async def cmd_health(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
    health_url = APP_BASE_URL.rsplit("/", 1)[0] + "/healthz"

    try:
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get(health_url, timeout=10) as resp:
                    if resp.status == 200:
                        await update.message.reply_text("💚 app-ollama è raggiungibile.")
                        return
            except Exception:
                pass
            ans = await query_app_ollama(session, "ping", _get_model_for_chat(update.effective_chat.id))
    except Exception as e:
        ans = f"(errore: {e})"

    if ans.startswith("(errore"):
        await update.message.reply_text(f"💥 app-ollama non raggiungibile:\n{ans}")
    else:
        await update.message.reply_text("💚 app-ollama risponde correttamente.")

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    text_in = (update.message.text or "").strip()
    if not text_in:
        return

    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
    model = _get_model_for_chat(update.effective_chat.id)

    async with aiohttp.ClientSession() as session:
        reply = await query_app_ollama(session, text_in, model)

    for chunk in chunk_text(reply):
        try:
            await update.message.reply_text(chunk)
        except TelegramError:
            await update.message.reply_text(chunk)

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    Gestisce messaggi vocali (voice) e note audio (audio).
    Scarica OGG/OPUS, converte e trascrive con faster-whisper, poi interroga app-ollama.
    """
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    # voice (OGG/OPUS) o audio (potrebbe essere anche MP3/ogg)
    file_id = None
    if update.message.voice:
        file_id = update.message.voice.file_id
    elif update.message.audio:
        file_id = update.message.audio.file_id
    else:
        return

    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    try:
        tg_file = await context.bot.get_file(file_id)
        # scarica bytes
        ogg_bytes = await tg_file.download_as_bytearray()
    except Exception as e:
        await update.message.reply_text(f"💥 Errore nel download dell'audio: {e}")
        return

    # trascrizione
    try:
        await update.message.reply_text("📝 Sto trascrivendo il messaggio vocale…")
        text = await transcribe_voice_ogg_to_text(bytes(ogg_bytes))
        if not text:
            await update.message.reply_text("⚠️ Non sono riuscito a capire il contenuto audio.")
            return
        await update.message.reply_text(f"✍️ Trascrizione: {text}")
    except Exception as e:
        await update.message.reply_text(f"💥 Errore in trascrizione: {e}\nAssicurati di avere ffmpeg installato e faster-whisper nel venv.")
        return

    # invia la trascrizione a app-ollama
    model = _get_model_for_chat(update.effective_chat.id)
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    async with aiohttp.ClientSession() as session:
        reply = await query_app_ollama(session, text, model)

    for chunk in chunk_text(reply):
        try:
            await update.message.reply_text(chunk)
        except TelegramError:
            await update.message.reply_text(chunk)

# =============== Error handler ===============
async def on_error(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    print(f"[PTB ERROR] Update: {update}\nException: {context.error}", file=sys.stderr)

# =============== Main ===============
def main():
    print(f"[INFO] Avvio Telegram bridge → {APP_BASE_URL} | default model: {DEFAULT_MODEL}", file=sys.stderr)
    if ALLOWED_CHAT_IDS:
        print(f"[INFO] Chat autorizzate: {sorted(ALLOWED_CHAT_IDS)}", file=sys.stderr)

    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("model", cmd_model))
    app.add_handler(CommandHandler("health", cmd_health))

    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))
    # voice note (microfono) e audio
    app.add_handler(MessageHandler(filters.VOICE, on_voice))
    app.add_handler(MessageHandler(filters.AUDIO, on_voice))

    app.add_error_handler(on_error)

    app.run_polling(allowed_updates=Update.ALL_TYPES, close_loop=False)

if __name__ == "__main__":
    main()
