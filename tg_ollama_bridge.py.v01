#!/usr/bin/python3
# -*- coding: utf-8 -*-
import os
import sys
import json
import html
from typing import Dict

import aiohttp
from telegram import Update
from telegram.constants import ParseMode, ChatAction
from telegram.error import BadRequest, TelegramError
from telegram.ext import (
    ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters
)

BASE_PATH = os.path.abspath("./")
CFG_PATH = os.path.join(BASE_PATH, "config", "telegram.json")

# === Config load ===
if not os.path.exists(CFG_PATH):
    print(f"[ERRORE] Config Telegram mancante: {CFG_PATH}", file=sys.stderr)
    sys.exit(1)

try:
    with open(CFG_PATH, "r", encoding="utf-8") as f:
        CFG = json.load(f)
except Exception as e:
    print(f"[ERRORE] Impossibile leggere/parsare {CFG_PATH}: {e}", file=sys.stderr)
    sys.exit(1)

BOT_TOKEN: str = (CFG.get("bot_token") or "").strip()
APP_BASE_URL: str = (CFG.get("app_base_url") or "http://127.0.0.1:5000/json").rstrip("/")
DEFAULT_MODEL: str = CFG.get("default_model", "gemma2:2b")
ALLOWED_CHAT_IDS = set(CFG.get("allowed_chat_ids", []))
TIMEOUT_SEC: int = int(CFG.get("timeout_sec", 60))

if not BOT_TOKEN:
    print("[ERRORE] bot_token non impostato in config/telegram.json", file=sys.stderr)
    sys.exit(1)

# === Per-chat state (modello selezionato) ===
CHAT_MODEL: Dict[int, str] = {}

def _is_allowed(chat_id: int) -> bool:
    return (not ALLOWED_CHAT_IDS) or (chat_id in ALLOWED_CHAT_IDS)

def _get_model_for_chat(chat_id: int) -> str:
    return CHAT_MODEL.get(chat_id, DEFAULT_MODEL)

def _set_model_for_chat(chat_id: int, model: str):
    CHAT_MODEL[chat_id] = (model or "").strip()

def chunk_text(text: str, max_len: int = 3800):
    """Spezza testo lungo in blocchi per Telegram (limite ~4096)."""
    text = text or ""
    for i in range(0, len(text), max_len):
        yield text[i:i+max_len]

async def query_app_ollama(session: aiohttp.ClientSession, text: str, model: str) -> str:
    """
    Tenta POST JSON su /json (body: {"query": "...", "model": "..."})
    Se fallisce, fallback GET con querystring.
    """
    url = APP_BASE_URL  # es: http://127.0.0.1:5000/json

    # --- Tentativo POST JSON ---
    try:
        async with session.post(
            url,
            json={"query": text, "model": model},
            timeout=TIMEOUT_SEC
        ) as resp:
            if resp.status == 200:
                data = await resp.json()
                if isinstance(data, dict):
                    return str(data.get("response", "")) or "(risposta vuota)"
            # altrimenti, riprova in GET
    except Exception:
        pass

    # --- Fallback GET ---
    try:
        params = {"query": text, "model": model}
        async with session.get(url, params=params, timeout=TIMEOUT_SEC) as resp:
            if resp.status == 200:
                data = await resp.json()
                if isinstance(data, dict):
                    return str(data.get("response", "")) or "(risposta vuota)"
            return f"(errore: server ha risposto {resp.status} su GET {url})"
    except Exception as e:
        return f"(errore: impossibile contattare l'app Ollama {url} â€” {e})"

def _html(msg: str) -> str:
    """Escape HTML per evitare errori di parsing con ParseMode.HTML."""
    return html.escape(msg or "")

# =======================
#       Handlers
# =======================
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    model = _get_model_for_chat(update.effective_chat.id)
    body = (
        "ðŸ‘‹ Ciao! Questo bot inoltra i tuoi messaggi a <b>app-ollama.py</b> e ti restituisce la risposta.<br><br>"
        f"â€¢ Endpoint: <code>{_html(APP_BASE_URL)}</code><br>"
        f"â€¢ Modello attuale: <code>{_html(model)}</code><br><br>"
        "<b>Comandi utili</b><br>"
        "â€¢ <code>/model &lt;nome_modello&gt;</code> â€” imposta il modello (es. <code>gemma2:2b</code>, <code>llama3:latest</code>)<br>"
        "â€¢ <code>/health</code> â€” verifica connessione con l'app<br>"
        "Scrivi un messaggio e lo invio al modello."
    )
    try:
        await update.message.reply_text(body, parse_mode=ParseMode.HTML, disable_web_page_preview=True)
    except BadRequest as e:
        # fallback senza parse mode in caso di problemi di parsing
        await update.message.reply_text(
            f"Ciao! Endpoint: {APP_BASE_URL}\nModello: {model}\nUsa /model <nome_modello> o /health",
        )

async def cmd_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    if not context.args:
        current = _get_model_for_chat(update.effective_chat.id)
        await update.message.reply_text(
            f"Modello attuale: <code>{_html(current)}</code>\nUsa: <code>/model &lt;nome&gt;</code>",
            parse_mode=ParseMode.HTML,
        )
        return

    model = " ".join(context.args).strip()
    _set_model_for_chat(update.effective_chat.id, model)
    await update.message.reply_text(
        f"âœ… Modello impostato su: <code>{_html(model)}</code>",
        parse_mode=ParseMode.HTML,
    )

async def cmd_health(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return
    # typing indicator
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    # prova /healthz, altrimenti query fittizia
    health_url = APP_BASE_URL.rsplit("/", 1)[0] + "/healthz"
    try:
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get(health_url, timeout=10) as resp:
                    if resp.status == 200:
                        await update.message.reply_text("ðŸ’š app-ollama Ã¨ raggiungibile.")
                        return
            except Exception:
                pass
            ans = await query_app_ollama(session, "ping", _get_model_for_chat(update.effective_chat.id))
    except Exception as e:
        ans = f"(errore: {e})"

    if ans.startswith("(errore"):
        await update.message.reply_text(f"ðŸ’¥ app-ollama non raggiungibile:\n{ans}")
    else:
        await update.message.reply_text("ðŸ’š app-ollama risponde correttamente.")

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    text_in = (update.message.text or "").strip()
    if not text_in:
        return

    # typing indicator corretto (PTB v20)
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    model = _get_model_for_chat(update.effective_chat.id)

    async with aiohttp.ClientSession() as session:
        reply = await query_app_ollama(session, text_in, model)

    # invia a blocchi se troppo lungo
    for chunk in chunk_text(reply):
        try:
            await update.message.reply_text(chunk)
        except TelegramError:
            # fallback senza parse mode / safe content
            await update.message.reply_text(chunk)

# =======================
#   Error handler PTB
# =======================
async def on_error(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    print(f"[PTB ERROR] Update: {update}\nException: {context.error}", file=sys.stderr)

def main():
    print(f"[INFO] Avvio Telegram bridge â†’ {APP_BASE_URL} | default model: {DEFAULT_MODEL}", file=sys.stderr)
    if ALLOWED_CHAT_IDS:
        print(f"[INFO] Chat autorizzate: {sorted(ALLOWED_CHAT_IDS)}", file=sys.stderr)

    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("model", cmd_model))
    app.add_handler(CommandHandler("health", cmd_health))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    # registra handler errori per tracciare stacktrace invece del warning "No error handlers"
    app.add_error_handler(on_error)

    app.run_polling(allowed_updates=Update.ALL_TYPES, close_loop=False)

if __name__ == "__main__":
    main()
#!/usr/bin/python3
# -*- coding: utf-8 -*-
import os
import sys
import json
import html
from typing import Dict

import aiohttp
from telegram import Update
from telegram.constants import ParseMode, ChatAction
from telegram.error import BadRequest, TelegramError
from telegram.ext import (
    ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters
)

BASE_PATH = os.path.abspath("./")
CFG_PATH = os.path.join(BASE_PATH, "config", "telegram.json")

# === Config load ===
if not os.path.exists(CFG_PATH):
    print(f"[ERRORE] Config Telegram mancante: {CFG_PATH}", file=sys.stderr)
    sys.exit(1)

try:
    with open(CFG_PATH, "r", encoding="utf-8") as f:
        CFG = json.load(f)
except Exception as e:
    print(f"[ERRORE] Impossibile leggere/parsare {CFG_PATH}: {e}", file=sys.stderr)
    sys.exit(1)

BOT_TOKEN: str = (CFG.get("bot_token") or "").strip()
APP_BASE_URL: str = (CFG.get("app_base_url") or "http://127.0.0.1:5000/json").rstrip("/")
DEFAULT_MODEL: str = CFG.get("default_model", "gemma2:2b")
ALLOWED_CHAT_IDS = set(CFG.get("allowed_chat_ids", []))
TIMEOUT_SEC: int = int(CFG.get("timeout_sec", 60))

if not BOT_TOKEN:
    print("[ERRORE] bot_token non impostato in config/telegram.json", file=sys.stderr)
    sys.exit(1)

# === Per-chat state (modello selezionato) ===
CHAT_MODEL: Dict[int, str] = {}

def _is_allowed(chat_id: int) -> bool:
    return (not ALLOWED_CHAT_IDS) or (chat_id in ALLOWED_CHAT_IDS)

def _get_model_for_chat(chat_id: int) -> str:
    return CHAT_MODEL.get(chat_id, DEFAULT_MODEL)

def _set_model_for_chat(chat_id: int, model: str):
    CHAT_MODEL[chat_id] = (model or "").strip()

def chunk_text(text: str, max_len: int = 3800):
    """Spezza testo lungo in blocchi per Telegram (limite ~4096)."""
    text = text or ""
    for i in range(0, len(text), max_len):
        yield text[i:i+max_len]

async def query_app_ollama(session: aiohttp.ClientSession, text: str, model: str) -> str:
    """
    Tenta POST JSON su /json (body: {"query": "...", "model": "..."})
    Se fallisce, fallback GET con querystring.
    """
    url = APP_BASE_URL  # es: http://127.0.0.1:5000/json

    # --- Tentativo POST JSON ---
    try:
        async with session.post(
            url,
            json={"query": text, "model": model},
            timeout=TIMEOUT_SEC
        ) as resp:
            if resp.status == 200:
                data = await resp.json()
                if isinstance(data, dict):
                    return str(data.get("response", "")) or "(risposta vuota)"
            # altrimenti, riprova in GET
    except Exception:
        pass

    # --- Fallback GET ---
    try:
        params = {"query": text, "model": model}
        async with session.get(url, params=params, timeout=TIMEOUT_SEC) as resp:
            if resp.status == 200:
                data = await resp.json()
                if isinstance(data, dict):
                    return str(data.get("response", "")) or "(risposta vuota)"
            return f"(errore: server ha risposto {resp.status} su GET {url})"
    except Exception as e:
        return f"(errore: impossibile contattare l'app Ollama {url} â€” {e})"

def _html(msg: str) -> str:
    """Escape HTML per evitare errori di parsing con ParseMode.HTML."""
    return html.escape(msg or "")

# =======================
#       Handlers
# =======================
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    model = _get_model_for_chat(update.effective_chat.id)
    body = (
        "ðŸ‘‹ Ciao! Questo bot inoltra i tuoi messaggi a <b>app-ollama.py</b> e ti restituisce la risposta.<br><br>"
        f"â€¢ Endpoint: <code>{_html(APP_BASE_URL)}</code><br>"
        f"â€¢ Modello attuale: <code>{_html(model)}</code><br><br>"
        "<b>Comandi utili</b><br>"
        "â€¢ <code>/model &lt;nome_modello&gt;</code> â€” imposta il modello (es. <code>gemma2:2b</code>, <code>llama3:latest</code>)<br>"
        "â€¢ <code>/health</code> â€” verifica connessione con l'app<br>"
        "Scrivi un messaggio e lo invio al modello."
    )
    try:
        await update.message.reply_text(body, parse_mode=ParseMode.HTML, disable_web_page_preview=True)
    except BadRequest as e:
        # fallback senza parse mode in caso di problemi di parsing
        await update.message.reply_text(
            f"Ciao! Endpoint: {APP_BASE_URL}\nModello: {model}\nUsa /model <nome_modello> o /health",
        )

async def cmd_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    if not context.args:
        current = _get_model_for_chat(update.effective_chat.id)
        await update.message.reply_text(
            f"Modello attuale: <code>{_html(current)}</code>\nUsa: <code>/model &lt;nome&gt;</code>",
            parse_mode=ParseMode.HTML,
        )
        return

    model = " ".join(context.args).strip()
    _set_model_for_chat(update.effective_chat.id, model)
    await update.message.reply_text(
        f"âœ… Modello impostato su: <code>{_html(model)}</code>",
        parse_mode=ParseMode.HTML,
    )

async def cmd_health(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return
    # typing indicator
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    # prova /healthz, altrimenti query fittizia
    health_url = APP_BASE_URL.rsplit("/", 1)[0] + "/healthz"
    try:
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get(health_url, timeout=10) as resp:
                    if resp.status == 200:
                        await update.message.reply_text("ðŸ’š app-ollama Ã¨ raggiungibile.")
                        return
            except Exception:
                pass
            ans = await query_app_ollama(session, "ping", _get_model_for_chat(update.effective_chat.id))
    except Exception as e:
        ans = f"(errore: {e})"

    if ans.startswith("(errore"):
        await update.message.reply_text(f"ðŸ’¥ app-ollama non raggiungibile:\n{ans}")
    else:
        await update.message.reply_text("ðŸ’š app-ollama risponde correttamente.")

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message:
        return
    if not _is_allowed(update.effective_chat.id):
        return

    text_in = (update.message.text or "").strip()
    if not text_in:
        return

    # typing indicator corretto (PTB v20)
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    model = _get_model_for_chat(update.effective_chat.id)

    async with aiohttp.ClientSession() as session:
        reply = await query_app_ollama(session, text_in, model)

    # invia a blocchi se troppo lungo
    for chunk in chunk_text(reply):
        try:
            await update.message.reply_text(chunk)
        except TelegramError:
            # fallback senza parse mode / safe content
            await update.message.reply_text(chunk)

# =======================
#   Error handler PTB
# =======================
async def on_error(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    print(f"[PTB ERROR] Update: {update}\nException: {context.error}", file=sys.stderr)

def main():
    print(f"[INFO] Avvio Telegram bridge â†’ {APP_BASE_URL} | default model: {DEFAULT_MODEL}", file=sys.stderr)
    if ALLOWED_CHAT_IDS:
        print(f"[INFO] Chat autorizzate: {sorted(ALLOWED_CHAT_IDS)}", file=sys.stderr)

    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("model", cmd_model))
    app.add_handler(CommandHandler("health", cmd_health))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    # registra handler errori per tracciare stacktrace invece del warning "No error handlers"
    app.add_error_handler(on_error)

    app.run_polling(allowed_updates=Update.ALL_TYPES, close_loop=False)

if __name__ == "__main__":
    main()
